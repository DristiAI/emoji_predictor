{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils import *\n",
    "from keras.layers import Input,Dense,LSTM\n",
    "import numpy as np\n",
    "import keras,keras.backend as K\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './data/emojify_data.csv'\n",
    "TEST_PATH = './data/test_emoji.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , train_labels = read_csv(TRAIN_PATH)\n",
    "test_data,test_labels = read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she got me a nice present ‚ù§\n",
      "will you be my valentine ‚ù§\n",
      "you brighten my day ‚ù§\n",
      "I hate u üòû\n",
      "I want food üç¥\n"
     ]
    }
   ],
   "source": [
    "def view(l,see_):\n",
    "    for i,sent in enumerate(l) :\n",
    "        print(sent,emojize(see_[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(batch_x,batch_y):\n",
    "    max_len = batch_maxlen(batch_x)\n",
    "    time_steps=max_len\n",
    "    dim=100\n",
    "    sequences=[]\n",
    "    for sentence in batch_x:\n",
    "        words = sentence.strip().lower().split()\n",
    "        sequence = []\n",
    "        padding = max_len - len(words)\n",
    "        words = words + ['unkwnval']*padding\n",
    "        #print(words)\n",
    "        for word in words: \n",
    "            sequence.append(nlp(word).vector[:128])\n",
    "        sequences.append(sequence)\n",
    "    return np.array(sequences),batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_x,batches_y = create_batches(train_data,train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 183 training sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using word2vec vectors from spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_():\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=[None,128]))\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(LSTM(128,return_sequences=False))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = model_()\n",
    "opt= keras.optimizers.adam(lr=0.001)\n",
    "Model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "allbatch=[]\n",
    "for batch_x,batch_y in zip(batches_x,batches_y):\n",
    "    allbatch.append(create_sequences(batch_x,batch_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 264,837\n",
      "Trainable params: 264,325\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take the batch's maximum length as the number of time steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 1.6026 - acc: 0.0938\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.6029 - acc: 0.2692\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2998 - acc: 0.7812\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.1879 - acc: 0.6154\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9095 - acc: 0.8750\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7190 - acc: 0.7308\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5200 - acc: 0.9062\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2758 - acc: 0.9615\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3185 - acc: 0.8750\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.1671 - acc: 0.9231\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1630 - acc: 0.9062\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.2308 - acc: 0.9615\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0937 - acc: 0.9615\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1026 - acc: 0.9615\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(8):\n",
    "    for batches in allbatch:\n",
    "        batch_x,batch_y =batches\n",
    "        #print(batch_y)\n",
    "        batch_y = batch_y.astype(np.float)\n",
    "        Model.fit(batch_x,batch_y,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_x,batches_y = create_batches(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=create_sequences(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(Model.predict(x[0]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label=test_labels.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY 0.965517241379\n"
     ]
    }
   ],
   "source": [
    "print('TEST ACCURACY',sum(y_pred==test_label)/58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test sentence emoji  predicted emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\t üç¥ üç¥\n",
      "he did not answer\t üòû üòû\n",
      "he got a raise\t üòÑ üòÑ\n",
      "she got me a present\t ‚ù§ ‚ù§\n",
      "ha ha ha it was so funny\t üòÑ üòÑ\n",
      "he is a good friend\t ‚ù§ ‚ù§\n",
      "I am upset\t üòû üòû\n",
      "We had such a lovely dinner tonight\t ‚ù§ ‚ù§\n",
      "where is the food\t üç¥ üç¥\n",
      "Stop making this joke ha ha ha\t üòÑ üòÑ\n",
      "where is the ball\t ‚öæ ‚öæ\n",
      "work is hard\t üòû üòû\n",
      "This girl is messing with me\t üòû üòû\n",
      "are you serious ha ha\t üòÑ üòÑ\n",
      "Let us go play baseball\t ‚öæ ‚öæ\n",
      "This stupid grader is not working \t üòû üòû\n",
      "work is horrible\t üòû üòû\n",
      "Congratulation for having a baby\t üòÑ üòÑ\n",
      "stop messing around\t üòû üòû\n",
      "any suggestions for dinner\t üç¥ üç¥\n",
      "I love taking breaks\t ‚ù§ ‚ù§\n",
      "you brighten my day\t üòÑ ‚ù§\n",
      "I boiled rice\t üç¥ üç¥\n",
      "she is a bully\t üòû üòû\n",
      "Why are you feeling bad\t üòû üòû\n",
      "I am upset\t üòû üòû\n",
      "I worked during my birthday\t üòû üòû\n",
      "My grandmother is the love of my life\t ‚ù§ ‚ù§\n",
      "enjoy your break\t üòÑ üòÑ\n",
      "valentine day is near\t ‚ù§ ‚ù§\n",
      "I miss you so much\t ‚ù§ ‚ù§\n",
      "throw the ball\t ‚öæ ‚öæ\n",
      "My life is so boring\t üòû üòû\n",
      "she said yes\t üòÑ üòÑ\n",
      "will you be my valentine\t ‚ù§ ‚ù§\n",
      "he can pitch really well\t ‚öæ ‚öæ\n",
      "dance with me\t üòÑ üòÑ\n",
      "I am starving\t üç¥ üç¥\n",
      "See you at the restaurant\t üç¥ üç¥\n",
      "I like to laugh\t üòÑ üòÑ\n",
      "I will go dance üòÑ üòÑ\n",
      "I like your jacket \t üòÑ üòÑ\n",
      "i miss her\t üòû üòû\n",
      "what is your favorite baseball game\t ‚öæ ‚öæ\n",
      "Good job\t üòÑ üòÑ\n",
      "I love to the stars and back\t ‚ù§ ‚ù§\n",
      "What you did was awesome\t üòÑ üòÑ\n",
      "ha ha ha lol\t üòÑ üòÑ\n",
      "I want to joke\t üòÑ üòÑ\n",
      "go away\t üòû üòû\n",
      "yesterday we lost again\t üòû üòû\n",
      "family is all I have\t ‚ù§ ‚ù§\n",
      "you are failing this exercise\t üòû üòû\n",
      "Good joke\t üòÑ üòÑ\n",
      "You totally deserve this prize\t üòÑ üòÑ\n",
      "I did not have breakfast  üòû üòû\n",
      "I am hungry  üòû üç¥\n",
      "I want to eat  üç¥ üç¥\n"
     ]
    }
   ],
   "source": [
    "for i,sent in enumerate(test_data) :\n",
    "    print(sent,emojize(test_label[i]),emojize(y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LET'S TRY OWN DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = ['This world is a hard place to live',\n",
    "                    'He is a weak boy',\n",
    "                    'What a wonderful scenery',\n",
    "                    'Nice to meet you',\n",
    "                    'What do you want for food',\n",
    "                    'I adore his kindness',\n",
    "                    'I am going to play cricket',\n",
    "                    'He won the match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 4 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(Model.predict(create_sequence(random_sentences)),axis=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 4 2 0 1]\n",
      "This world is a hard place to live ‚ù§\n",
      "He is a weak boy ‚ù§\n",
      "What a wonderful scenery üòÑ\n",
      "Nice to meet you ‚ù§\n",
      "What do you want for food üç¥\n",
      "I adore his kindness üòÑ\n",
      "I am going to play cricket ‚ù§\n",
      "He won the match ‚öæ\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(Model.predict(create_sequence(random_sentences)),axis=1)\n",
    "print(predictions)\n",
    "view(random_sentences,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
